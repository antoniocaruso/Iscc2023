@article{LiSurvey2021,
    title = {Image retrieval from remote sensing big data: A survey},
    journal = {Information Fusion},
    volume = {67},
    pages = {94-115},
    year = {2021},
    issn = {1566-2535},
    doi = {https://doi.org/10.1016/j.inffus.2020.10.008},
%    url = {https://www.sciencedirect.com/science/article/pii/S1566253520303778},
    author = {Yansheng Li and Jiayi Ma and Yongjun Zhang},
    keywords = {Remote sensing (rs) big data, Rs image retrieval methods, Rs image retrieval applications, Evaluation datasets and performance discussion, Future research directions}
}

@inproceedings{odc,
author = {Killough, Brian},
year = {2018},
month = {07},
pages = {8629-8632},
title = {Overview of the Open Data Cube Initiative},
doi = {10.1109/IGARSS.2018.8517694}
}

@ARTICLE{Adao2017,
	author = {Adão, Telmo and Hruška, Jonáš and Pádua, Luís and Bessa, José and Peres, Emanuel and Morais, Raul and Sousa, Joaquim João},
	title = {Hyperspectral imaging: A review on UAV-based sensors, data processing and applications for agriculture and forestry},
	year = {2017},
	journal = {Remote Sensing},
	volume = {9},
	number = {11},
	doi = {10.3390/rs9111110},
%	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034756154&doi=10.3390},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 572; All Open Access, Gold Open Access, Green Open Access}
}


@Article{agriengineering4020029,
AUTHOR = {Yadav, Sargam and Kaushik, Abhishek and Sharma, Mahak and Sharma, Shubham},
TITLE = {Disruptive Technologies in Smart Farming: An Expanded View with Sentiment Analysis},
JOURNAL = {AgriEngineering},
VOLUME = {4},
YEAR = {2022},
NUMBER = {2},
PAGES = {424--460},
% URL = {https://www.mdpi.com/2624-7402/4/2/29},
ISSN = {2624-7402},
ABSTRACT = {Smart Farming (SF) is an emerging technology in the current agricultural landscape. The aim of Smart Farming is to provide tools for various agricultural and farming operations to improve yield by reducing cost, waste, and required manpower. SF is a data-driven approach that can mitigate losses that occur due to extreme weather conditions and calamities. The influx of data from various sensors, and the introduction of information communication technologies (ICTs) in the field of farming has accelerated the implementation of disruptive technologies (DTs) such as machine learning and big data. Application of these predictive and innovative tools in agriculture is crucial for handling unprecedented conditions such as climate change and the increasing global population. In this study, we review the recent advancements in the field of Smart Farming, which include novel use cases and projects around the globe. An overview of the challenges associated with the adoption of such technologies in their respective regions is also provided. A brief analysis of the general sentiment towards Smart Farming technologies is also performed by manually annotating YouTube comments and making use of the pattern library. Preliminary findings of our study indicate that, though there are several barriers to the implementation of SF tools, further research and innovation can alleviate such risks and ensure sustainability of the food supply. The exploratory sentiment analysis also suggests that most digital users are not well-informed about such technologies.},
DOI = {10.3390/agriengineering4020029}
}

@article{de2018agriculture,
  title={Agriculture 4.0: The future of farming technology},
  author={De Clercq, Matthieu and Vats, Anshu and Biel, Alvaro},
  journal={Proceedings of the World Government Summit, Dubai, UAE},
  pages={11--13},
  year={2018},
  publisher={IEEE}
}

@online{mcfadden2023precision,
  title={Precision Agriculture in the Digital Era: Recent Adoption on US Farms},
  author={McFadden, Jonathan and Njuki, Eric and Griffin, Terry},
  year={2023}
  %url = {https://www.ers.usda.gov/webdocs/publications/105894/eib-248.pdf?v=9219.8}
}

@article{lu_survey_2020,
	title = {A survey of public datasets for computer vision tasks in precision agriculture},
	volume = {178},
	issn = {01681699},
%	url = {https://linkinghub.elsevier.com/retrieve/pii/S0168169920312709},
	doi = {10.1016/j.compag.2020.105760},
	pages = {105760},
	journaltitle = {Computers and Electronics in Agriculture},
	shortjournal = {Computers and Electronics in Agriculture},
	author = {Lu, Yuzhen and Young, Sierra},
	%urldate = {2023-03-13},
	date = {2020-11},
	langid = {english},
}

@article{bouguettaya_deep_2022,
	title = {Deep learning techniques to classify agricultural crops through {UAV} imagery: a review},
	volume = {34},
	issn = {0941-0643, 1433-3058},
%	url = {https://link.springer.com/10.1007/s00521-022-07104-9},
	doi = {10.1007/s00521-022-07104-9},
	pages = {9511--9536},
	number = {12},
	journaltitle = {Neural Computing and Applications},
	shortjournal = {Neural Comput \& Applic},
	author = {Bouguettaya, Abdelmalek and Zarzour, Hafed and Kechida, Ahmed and Taberkit, Amine Mohammed},
	%urldate = {2023-03-13},
	date = {2022-06},
	langid = {english},
}

@Article{s21051617,
    AUTHOR = {Safonova, Anastasiia and Guirado, Emilio and Maglinets, Yuriy and Alcaraz-Segura, Domingo and Tabik, Siham},
    TITLE = {Olive Tree Biovolume from UAV Multi-Resolution Image Segmentation with Mask R-CNN},
    JOURNAL = {Sensors},
    VOLUME = {21},
    YEAR = {2021},
    NUMBER = {5},
    ARTICLE-NUMBER = {1617},
  %  URL = {https://www.mdpi.com/1424-8220/21/5/1617},
    PubMedID = {33668984},
    ISSN = {1424-8220},
    DOI = {10.3390/s21051617},
    keywords={rel_wor}
}

@ARTICLE{Egli20201,
	author = {Egli, Sebastian and Höpke, Martin},
	title = {Cnn-based tree species classification using high resolution rgb image data from automated uav observations},
	year = {2020},
	journal = {Remote Sensing},
	volume = {12},
	number = {23},
	pages = {1 – 17},
	doi = {10.3390/rs12233892},
%	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097031088&doi=10.3390%2frs12233892&partnerID=40&md5=9437792d192fe00c9cf06bf07a385a40},
	type = {Article},
	keywords = {rel_wor},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 18; All Open Access, Gold Open Access, Green Open Access}
}

@Article{rs14061523,
    AUTHOR = {Ye, Zhangxi and Wei, Jiahao and Lin, Yuwei and Guo, Qian and Zhang, Jian and Zhang, Houxi and Deng, Hui and Yang, Kaijie},
    TITLE = {Extraction of Olive Crown Based on UAV Visible Images and the U2-Net Deep Learning Model},
    JOURNAL = {Remote Sensing},
    VOLUME = {14},
    YEAR = {2022},
    NUMBER = {6},
    ARTICLE-NUMBER = {1523},
  %  URL = {https://www.mdpi.com/2072-4292/14/6/1523},
    ISSN = {2072-4292},
    DOI = {10.3390/rs14061523},
    keywords={rel_wor}
}

@article{ruswurm_multi-temporal_2018,
	title = {Multi-{Temporal} {Land} {Cover} {Classification} with {Sequential} {Recurrent} {Encoders}},
	volume = {7},
	issn = {2220-9964},
%	url = {http://arxiv.org/abs/1802.02080},
	doi = {10.3390/ijgi7040129},
	abstract = {Earth observation (EO) sensors deliver data at daily or weekly intervals. Most land use and land cover classiﬁcation (LULC) approaches, however, are designed for cloud-free and mono-temporal observations. The increasing temporal capabilities of today’s sensors enable the use of temporal, along with spectral and spatial features.Domains such as speech recognition or neural machine translation, work with inherently temporal data and, today, achieve impressive results by using sequential encoder-decoder structures. Inspired by these sequence-to-sequence models, we adapt an encoder structure with convolutional recurrent layers in order to approximate a phenological model for vegetation classes based on a temporal sequence of Sentinel 2 (S2) images. In our experiments, we visualize internal activations over a sequence of cloudy and non-cloudy images and ﬁnd several recurrent cells that reduce the input activity for cloudy observations. Hence, we assume that our network has learned cloud-ﬁltering schemes solely from input data, which could alleviate the need for tedious cloud-ﬁltering as a preprocessing step for many EO approaches. Moreover, using unﬁltered temporal series of top-of-atmosphere (TOA) reﬂectance data, our experiments achieved state-of-the-art classiﬁcation accuracies on a large number of crop classes with minimal preprocessing, compared to other classiﬁcation approaches.},
	language = {en},
	number = {4},
	%urldate = {2022-06-15},
	journal = {ISPRS International Journal of Geo-Information},
	author = {Rußwurm, Marc and Körner, Marco},
	year = {2018},
	note = {arXiv:1802.02080 [cs]},
	keywords = {sat},
	pages = {129},
}

@misc{daudt_fully_2018,
	title = {Fully {Convolutional} {Siamese} {Networks} for {Change} {Detection}},
	% url = {http://arxiv.org/abs/1810.08462},
	abstract = {This paper presents three fully convolutional neural network architectures which perform change detection using a pair of coregistered images. Most notably, we propose two Siamese extensions of fully convolutional networks which use heuristics about the current problem to achieve the best results in our tests on two open change detection datasets, using both RGB and multispectral images. We show that our system is able to learn from scratch using annotated change detection images. Our architectures achieve better performance than previously proposed methods, while being at least 500 times faster than related systems. This work is a step towards efﬁcient processing of data from large scale Earth observation systems such as Copernicus or Landsat.},
	language = {en},
	%urldate = {2022-07-12},
	publisher = {arXiv},
	author = {Daudt, Rodrigo Caye and Saux, Bertrand Le and Boulch, Alexandre},
	month = oct,
	year = {2018},
	note = {Number: arXiv:1810.08462 arXiv:1810.08462 [cs]},
	keywords = {sat},
%	file = {Daudt et al. - 2018 - Fully Convolutional Siamese Networks for Change De.pdf:/home/lore/Zotero/storage/L4UP7FIB/Daudt et al. - 2018 - Fully Convolutional Siamese Networks for Change De.pdf:application/pdf},
}

@article{ienco_land_2017,
	title = {Land {Cover} {Classification} via {Multi}-temporal {Spatial} {Data} by {Recurrent} {Neural} {Networks}},
	volume = {14},
	issn = {1545-598X, 1558-0571},
%	url = {http://arxiv.org/abs/1704.04055},
	doi = {10.1109/LGRS.2017.2728698},
	abstract = {Nowadays, modern earth observation programs produce huge volumes of satellite images time series (SITS) that can be useful to monitor geographical areas through time. How to efﬁciently analyze such kind of information is still an open question in the remote sensing ﬁeld. Recently, deep learning methods proved suitable to deal with remote sensing data mainly for scene classiﬁcation (i.e. Convolutional Neural Networks - CNNs - on single images) while only very few studies exist involving temporal deep learning approaches (i.e Recurrent Neural Networks - RNNs) to deal with remote sensing time series.},
	language = {en},
	number = {10},
	%urldate = {2022-06-15},
	journal = {IEEE Geoscience and Remote Sensing Letters},
	author = {Ienco, Dino and Gaetano, Raffaele and Dupaquier, Claire and Maurel, Pierre},
	month = oct,
	year = {2017},
	note = {arXiv:1704.04055 [cs]},
	keywords = {sat},
	pages = {1685--1689},
	file = {Ienco et al. - 2017 - Land Cover Classification via Multi-temporal Spati.pdf:/home/lore/Zotero/storage/AMTHB9DV/Ienco et al. - 2017 - Land Cover Classification via Multi-temporal Spati.pdf:application/pdf},
}

@misc{gurumurthy_mango_2019,
	title = {Mango {Tree} {Net} -- {A} fully convolutional network for semantic segmentation and individual crown detection of mango trees},
	% url = {http://arxiv.org/abs/1907.06915},
	abstract = {This work presents a method for semantic segmentation of mango trees in high resolution aerial imagery, and, a novel method for individual crown detection of mango trees using segmentation output. Mango Tree Net, a fully convolutional neural network (FCN), is trained using supervised learning to perform semantic segmentation of mango trees in imagery acquired using an unmanned aerial vehicle (UAV). The proposed network is retrained to separate touching/overlapping tree crowns in segmentation output. Contour based connected object detection is performed on the segmentation output from retrained network. Bounding boxes are drawn on the original images using coordinates of connected objects to achieve individual crown detection. The training dataset consists of 8, 824 image patches of size 240 × 240. The approach is tested for performance on segmentation and individual crown detection tasks using test datasets containing 36 and 4 images respectively. The performance is analyzed using standard metrics precision, recall, f1-score and accuracy. Results obtained demonstrate the robustness of the proposed methods despite variations in factors such as scale, occlusion, lighting conditions and surrounding vegetation.},
	language = {en},
	%urldate = {2022-10-26},
	publisher = {arXiv},
	author = {Gurumurthy, Vikas Agaradahalli and Kestur, Ramesh and Narasipura, Omkar},
	month = jul,
	year = {2019},
	note = {arXiv:1907.06915 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, rel_wor},
	file = {Gurumurthy et al. - 2019 - Mango Tree Net -- A fully convolutional network fo.pdf:/home/lore/Zotero/storage/95RHBGYH/Gurumurthy et al. - 2019 - Mango Tree Net -- A fully convolutional network fo.pdf:application/pdf},
}

@article{guirado_mask_2021,
	title = {Mask {R}-{CNN} and {OBIA} {Fusion} {Improves} the {Segmentation} of {Scattered} {Vegetation} in {Very} {High}-{Resolution} {Optical} {Sensors}},
	volume = {21},
	issn = {1424-8220},
%	url = {https://www.mdpi.com/1424-8220/21/1/320},
	doi = {10.3390/s21010320},
	abstract = {Vegetation generally appears scattered in drylands. Its structure, composition and spatial patterns are key controls of biotic interactions, water, and nutrient cycles. Applying segmentation methods to very high-resolution images for monitoring changes in vegetation cover can provide relevant information for dryland conservation ecology. For this reason, improving segmentation methods and understanding the effect of spatial resolution on segmentation results is key to improve dryland vegetation monitoring. We explored and analyzed the accuracy of Object-Based Image Analysis (OBIA) and Mask Region-based Convolutional Neural Networks (Mask R-CNN) and the fusion of both methods in the segmentation of scattered vegetation in a dryland ecosystem. As a case study, we mapped Ziziphus lotus, the dominant shrub of a habitat of conservation priority in one of the driest areas of Europe. Our results show for the ﬁrst time that the fusion of the results from OBIA and Mask R-CNN increases the accuracy of the segmentation of scattered shrubs up to 25\% compared to both methods separately. Hence, by fusing OBIA and Mask R-CNNs on very high-resolution images, the improved segmentation accuracy of vegetation mapping would lead to more precise and sensitive monitoring of changes in biodiversity and ecosystem services in drylands.},
	language = {en},
	number = {1},
	%urldate = {2022-10-26},
	journal = {Sensors},
	author = {Guirado, Emilio and Blanco-Sacristán, Javier and Rodríguez-Caballero, Emilio and Tabik, Siham and Alcaraz-Segura, Domingo and Martínez-Valderrama, Jaime and Cabello, Javier},
	month = jan,
	year = {2021},
	keywords={rel_wor},
	pages = {320},
	file = {Guirado et al. - 2021 - Mask R-CNN and OBIA Fusion Improves the Segmentati.pdf:/home/lore/Zotero/storage/KCYZYH5N/Guirado et al. - 2021 - Mask R-CNN and OBIA Fusion Improves the Segmentati.pdf:application/pdf},
}


@misc{ronneberger_u-net_2015,
	title = {{U-Net: Convolutional Networks for Biomedical Image Segmentation}},
%	url = {http://arxiv.org/abs/1505.04597},
%   urldate = {2022-07-13},
	shorttitle = {U-Net},
	number = {{arXiv}:1505.04597},
	publisher = {{arXiv}},
	author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
	date = {2015-05-18},
	langid = {english},
	eprinttype = {arxiv},
	%eprint = {1505.04597 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {Ronneberger et al. - 2015 - U-Net Convolutional Networks for Biomedical Image.pdf:/home/lore/Zotero/storage/XMPDRWWX/Ronneberger et al. - 2015 - U-Net Convolutional Networks for Biomedical Image.pdf:application/pdf},
}

@article{Mulla2013,
   abstract = {Precision agriculture dates back to the middle of the 1980's. Remote sensing applications in precision agriculture began with sensors for soil organic matter, and have quickly diversified to include satellite, aerial, and hand held or tractor mounted sensors. Wavelengths of electromagnetic radiation initially focused on a few key visible or near infrared bands. Today, electromagnetic wavelengths in use range from the ultraviolet to microwave portions of the spectrum, enabling advanced applications such as light detection and ranging (LiDAR), fluorescence spectroscopy, and thermal spectroscopy, along with more traditional applications in the visible and near infrared portions of the spectrum. Spectral bandwidth has decreased dramatically with the advent of hyperspectral remote sensing, allowing improved analysis of specific compounds, molecular interactions, crop stress, and crop biophysical or biochemical characteristics. A variety of spectral indices now exist for various precision agriculture applications, rather than a focus on only normalised difference vegetation indices. Spatial resolution of aerial and satellite remote sensing imagery has improved from 100's of m to sub-metre accuracy, allowing evaluation of soil and crop properties at fine spatial resolution at the expense of increased data storage and processing requirements. Temporal frequency of remote sensing imagery has also improved dramatically. At present there is considerable interest in collecting remote sensing data at multiple times in order to conduct near real time soil, crop and pest management. © 2012 IAgrE.},
   author = {David J. Mulla},
   doi = {10.1016/J.BIOSYSTEMSENG.2012.08.009},
   issn = {15375110},
   issue = {4},
   journal = {Biosystems Engineering},
   pages = {358-371},
   publisher = {Academic Press},
   title = {Twenty five years of remote sensing in precision agriculture: Key advances and remaining knowledge gaps},
   volume = {114},
   year = {2013},
}
@article{Meyer2008,
   abstract = {An accurate vegetation index is required to identify plant biomass versus soil and residue backgrounds for automated remote sensing and machine vision applications, plant ecological assessments, precision crop management, and weed control. An improved vegetation index, Excess Green minus Excess Red (ExG - ExR) was compared to the commonly used Excess Green (ExG), and the normalized difference (NDI) indices. The latter two indices used an Otsu threshold value to convert the index near-binary to a full-binary image. The indices were tested with digital color image sets of single plants grown and taken in a greenhouse and field images of young soybean plants. Vegetative index accuracies using a separation quality factor algorithm were compared to hand-extracted plant regions of interest. A quality factor of one represented a near perfect binary match of the computer extracted plant target compared to the hand-extracted plant region. The ExG - ExR index had the highest quality factor of 0.88 ± 0.12 for all three weeks and soil-residue backgrounds for the greenhouse set. The ExG + Otsu and NDI - Otsu indices had similar but lower quality factors of 0.53 ± 0.39 and 0.54 ± 0.33 for the same sets, respectively. Field images of young soybeans against bare soil gave quality factors for both ExG - ExR and ExG + Otsu around 0.88 ± 0.07. The quality factor of NDI + Otsu using the same field images was 0.25 ± 0.08. The ExG - ExR index has a fixed, built-in zero threshold, so it does not need Otsu or any user selected threshold value. The ExG - ExR index worked especially well for fresh wheat straw backgrounds, where it was generally 55\% more accurate than the ExG + Otsu and NDI + Otsu indices. Once a binary plant region of interest is identified with a vegetation index, other advanced image processing operations may be applied, such as identification of plant species for strategic weed control. © 2008 Elsevier B.V. All rights reserved.},
   author = {George E. Meyer and João Camargo Neto},
   doi = {10.1016/J.COMPAG.2008.03.009},
   issn = {01681699},
   issue = {2},
   journal = {Computers and Electronics in Agriculture},
   keywords = {Color images,Machine vision,Plant,Residue,Soil,Vegetation index},
   month = {10},
   pages = {282-293},
   title = {Verification of color vegetation indices for automated crop imaging applications},
   volume = {63},
   year = {2008},
}
@article{Kamilaris2017,
   abstract = {To tackle the increasing challenges of agricultural production, the complex agricultural ecosystems need to be better understood. This can happen by means of modern digital technologies that monitor continuously the physical environment, producing large quantities of data in an unprecedented pace. The analysis of this (big) data would enable farmers and companies to extract value from it, improving their productivity. Although big data analysis is leading to advances in various industries, it has not yet been widely applied in agriculture. The objective of this paper is to perform a review on current studies and research works in agriculture which employ the recent practice of big data analysis, in order to solve various relevant problems. Thirty-four different studies are presented, examining the problem they address, the proposed solution, tools, algorithms and data used, nature and dimensions of big data employed, scale of use as well as overall impact. Concluding, our review highlights the large opportunities of big data analysis in agriculture towards smarter farming, showing that the availability of hardware and software, techniques and methods for big data analysis, as well as the increasing openness of big data sources, shall encourage more academic research, public sector initiatives and business ventures in the agricultural sector. This practice is still at an early development stage and many barriers need to be overcome.},
   author = {Andreas Kamilaris and Andreas Kartakoullis and Francesc X. Prenafeta-Boldú},
   doi = {10.1016/J.COMPAG.2017.09.037},
   issn = {01681699},
   journal = {Computers and Electronics in Agriculture},
   keywords = {Agriculture,Big data analysis,Smart Farming,Survey},
   month = {12},
   pages = {23-37},
   publisher = {Elsevier B.V.},
   title = {A review on the practice of big data analysis in agriculture},
   volume = {143},
   year = {2017},
}
@article{Muangprathub2019,
   abstract = {In this paper, we propose developing a system optimally watering agricultural crops based on a wireless sensor network. This work aimed to design and develop a control system using node sensors in the crop field with data management via smartphone and a web application. The three components are hardware, web application, and mobile application. The first component was designed and implemented in control box hardware connected to collect data on the crops. Soil moisture sensors are used to monitor the field, connecting to the control box. The second component is a web-based application that was designed and implemented to manipulate the details of crop data and field information. This component applied data mining to analyze the data for predicting suitable temperature, humidity, and soil moisture for optimal future management of crops growth. The final component is mainly used to control crop watering through a mobile application in a smartphone. This allows either automatic or manual control by the user. The automatic control uses data from soil moisture sensors for watering. However, the user can opt for manual control of watering the crops in the functional control mode. The system can send notifications through LINE API for the LINE application. The system was implemented and tested in Makhamtia District, Suratthani Province, Thailand. The results showed the implementation to be useful in agriculture. The moisture content of the soil was maintained appropriately for vegetable growth, reducing costs and increasing agricultural productivity. Moreover, this work represents driving agriculture through digital innovation.},
   author = {Jirapond Muangprathub and Nathaphon Boonnam and Siriwan Kajornkasirat and Narongsak Lekbangpong and Apirat Wanichsombat and Pichetwut Nillaor},
   doi = {10.1016/J.COMPAG.2018.12.011},
   issn = {01681699},
   journal = {Computers and Electronics in Agriculture},
   keywords = {Agriculture data analysis,Data mining,IoTs,Knowledge discovery,Smart farm,Wireless sensor networks},
   month = {1},
   pages = {467-474},
   publisher = {Elsevier B.V.},
   title = {IoT and agriculture data analysis for smart farm},
   volume = {156},
   year = {2019},
}
@article{Farooq2019,
   abstract = {Internet of things (IoT) is a promising technology which provides efficient and reliable solutions towards the modernization of several domains. IoT based solutions are being developed to automatically maintain and monitor agricultural farms with minimal human involvement. The article presents many aspects of technologies involved in the domain of IoT in agriculture. It explains the major components of IoT based smart farming. A rigorous discussion on network technologies used in IoT based agriculture has been presented, that involves network architecture and layers, network topologies used, and protocols. Furthermore, the connection of IoT based agriculture systems with relevant technologies including cloud computing, big data storage and analytics has also been presented. In addition, security issues in IoT agriculture have been highlighted. A list of smart phone based and sensor based applications developed for different aspects of farm management has also been presented. Lastly, the regulations and policies made by several countries to standardize IoT based agriculture have been presented along with few available success stories. In the end, some open research issues and challenges in IoT agriculture field have been presented.},
   author = {Muhammad Shoaib Farooq and Shamyla Riaz and Adnan Abid and Kamran Abid and Muhammad Azhar Naeem},
   doi = {10.1109/ACCESS.2019.2949703},
   issn = {21693536},
   journal = {IEEE Access},
   keywords = {IoT,applications,architecture,challenges,industries,network,platforms,policies,protocols,security,smart farming,technologies},
   pages = {156237-156271},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {A Survey on the Role of IoT in Agriculture for the Implementation of Smart Farming},
   volume = {7},
   year = {2019},
}
@article{Guijarro2011,
   abstract = {One important issue emerging strongly in agriculture is related with the automatization of tasks, where the optical sensors play an important role. They provide images that must be conveniently processed. The most relevant image processing procedures require the identification of green plants, in our experiments they come from barley and corn crops including weeds, so that some types of action can be carried out, including site-specific treatments with chemical products or mechanical manipulations. Also the identification of textures belonging to the soil could be useful to know some variables, such as humidity, smoothness or any others. Finally, from the point of view of the autonomous robot navigation, where the robot is equipped with the imaging system, some times it is convenient to know not only the soil information and the plants growing in the soil but also additional information supplied by global references based on specific areas. This implies that the images to be processed contain textures of three main types to be identified: green plants, soil and sky if any. This paper proposes a new automatic approach for segmenting these main textures and also to refine the identification of sub-textures inside the main ones. Concerning the green identification, we propose a new approach that exploits the performance of existing strategies by combining them. The combination takes into account the relevance of the information provided by each strategy based on the intensity variability. This makes an important contribution. The combination of thresholding approaches, for segmenting the soil and the sky, makes the second contribution; finally the adjusting of the supervised fuzzy clustering approach for identifying sub-textures automatically, makes the third finding. The performance of the method allows to verify its viability for automatic tasks in agriculture based on image processing. © 2010 Elsevier B.V.},
   author = {M. Guijarro and G. Pajares and I. Riomoros and P. J. Herrera and X. P. Burgos-Artizzu and A. Ribeiro},
   doi = {10.1016/J.COMPAG.2010.09.013},
   issn = {01681699},
   issue = {1},
   journal = {Computers and Electronics in Agriculture},
   keywords = {Automatic tasks in agriculture,Image segmentation,Machine vision,Texture identification in crops},
   month = {1},
   pages = {75-83},
   title = {Automatic segmentation of relevant textures in agricultural images},
   volume = {75},
   year = {2011},
}
@article{Shamshiri2018,
   abstract = {Digital farming is the practice of modern technologies such as sensors, robotics, and data analysis for shifting from tedious operations to continuously automated processes. This paper reviews some of the latest achievements in agricultural robotics, specifically those that are used for autonomous weed control, field scouting, and harvesting. Object identification, task planning algorithms, digitalization and optimization of sensors are highlighted as some of the facing challenges in the context of digital farming. The concepts of multi-robots, human-robot collaboration, and environment reconstruction from aerial images and ground-based sensors for the creation of virtual farms were highlighted as some of the gateways of digital farming. It was shown that one of the trends and research focuses in agricultural field robotics is towards building a swarm of small scale robots and drones that collaborate together to optimize farming inputs and reveal denied or concealed information. For the case of robotic harvesting, an autonomous framework with several simple axis manipulators can be faster and more efficient than the currently adapted professional expensive manipulators. While robots are becoming the inseparable parts of the modern farms, our conclusion is that it is not realistic to expect an entirely automated farming system in the future.},
   author = {Redmond Ramin Shamshiri and Cornelia Weltzien and Ibrahim A. Hameed and Ian J. Yule and Tony E. Grift and Siva K. Balasundram and Lenka Pitonakova and Desa Ahmad and Girish Chowdhary},
   doi = {10.25165/IJABE.V11I4.4278},
   issn = {19346352},
   issue = {4},
   journal = {International Journal of Agricultural and Biological Engineering},
   keywords = {Agricultural robotics,Digital agriculture,Multi-robots,Precision agriculture,Simulation software,Virtual orchards},
   pages = {1-14},
   publisher = {Chinese Society of Agricultural Engineering},
   title = {Research and development in agricultural robotics: A perspective of digital farming},
   volume = {11},
   year = {2018},
}
@article{Bronson2016,
   abstract = {Farming is undergoing a digital revolution. Our existing review of current Big Data applications in the agri-food sector has revealed several collection and analytics tools that may have implications for relationships of power between players in the food system (e.g. between farmers and large corporations). For example, Who retains ownership of the data generated by applications like Monsanto Corproation's Weed I.D. “app”? Are there privacy implications with the data gathered by John Deere's precision agricultural equipment? Systematically tracing the digital revolution in agriculture, and charting the affordances as well as the limitations of Big Data applied to food and agriculture, should be a broad research goal for Big Data scholarship. Such a goal brings data scholarship into conversation with food studies and it allows for a focus on the material consequences of big data in society.},
   author = {Kelly Bronson and Irena Knezevic},
   doi = {10.1177/2053951716648174},
   issn = {20539517},
   issue = {1},
   journal = {Big Data and Society},
   keywords = {agribusiness,digital revolution in agriculture,farmers,material implications of big data,power},
   month = {1},
   publisher = {SAGE Publications Ltd},
   title = {Big Data in food and agriculture},
   volume = {3},
   year = {2016},
}
@article{Sishodia2020,
   abstract = {Agriculture provides for the most basic needs of humankind: food and fiber. The introduction of new farming techniques in the past century (e.g., during the Green Revolution) has helped agriculture keep pace with growing demands for food and other agricultural products. However, further increases in food demand, a growing population, and rising income levels are likely to put additional strain on natural resources. With growing recognition of the negative impacts of agriculture on the environment, new techniques and approaches should be able to meet future food demands while maintaining or reducing the environmental footprint of agriculture. Emerging technologies, such as geospatial technologies, Internet of Things (IoT), Big Data analysis, and artificial intelligence (AI), could be utilized to make informed management decisions aimed to increase crop production. Precision agriculture (PA) entails the application of a suite of such technologies to optimize agricultural inputs to increase agricultural production and reduce input losses. Use of remote sensing technologies for PA has increased rapidly during the past few decades. The unprecedented availability of high resolution (spatial, spectral and temporal) satellite images has promoted the use of remote sensing in many PA applications, including crop monitoring, irrigation management, nutrient application, disease and pest management, and yield prediction. In this paper, we provide an overview of remote sensing systems, techniques, and vegetation indices along with their recent (2015–2020) applications in PA. Remote-sensing-based PA technologies such as variable fertilizer rate application technology in Green Seeker and Crop Circle have already been incorporated in commercial agriculture. Use of unmanned aerial vehicles (UAVs) has increased tremendously during the last decade due to their cost-effectiveness and flexibility in obtaining the high-resolution (cm-scale) images needed for PA applications. At the same time, the availability of a large amount of satellite data has prompted researchers to explore advanced data storage and processing techniques such as cloud computing and machine learning. Given the complexity of image processing and the amount of technical knowledge and expertise needed, it is critical to explore and develop a simple yet reliable workflow for the real-time application of remote sensing in PA. Development of accurate yet easy to use, user-friendly systems is likely to result in broader adoption of remote sensing technologies in commercial and non-commercial PA applications.},
   author = {Rajendra P. Sishodia and Ram L. Ray and Sudhir K. Singh},
   doi = {10.3390/RS12193136},
   issn = {20724292},
   issue = {19},
   journal = {Remote Sensing},
   keywords = {Big data analysis,Disease and pest management,Nutrient management,Satellite remote sensing,UAV,Vegetation indices,Water management},
   month = {10},
   pages = {1-31},
   publisher = {MDPI AG},
   title = {Applications of remote sensing in precision agriculture: A review},
   volume = {12},
   year = {2020},
}
@article{Aker2016,
   abstract = {The widespread growth of information and telecommunication technologies (ICTs) in rural areas of developing countries offers new opportunities to provide more timely and low-cost information services to farmers, as well as assist in coordinating agricultural agents. Over the past decade, the number of public and private sector initiatives in this space has increased substantially, with over 140 deployments worldwide in 2015. While there is substantial potential for such services to address farmers’ and traders’ information and credit market constraints, economic research suggests that the impacts of such services on agricultural adoption, behavior and welfare is mixed. While this can, in part, be explained by the degree of the information asymmetry and the presence of other market failures in different contexts, research from other disciplines provides additional insights into these findings. In particular, work in the domain of human–computer interaction (HCI) focuses heavily on users’ interaction and experience with a given technology, thus explaining why users may not fully engage with ICT-based agricultural interfaces. Furthermore, sociological and anthropological approaches study the provision of information and trust and how these may be altered by ICT platforms. Drawing upon these disciplines, we suggest that future ICT for agriculture initiatives should first seek to better understand the information and complementary market failures in a given context, in order to better understand whether information is a binding constraint. Second, even if information is missing, the information services provided should be of high quality and from a trusted source, which can be a challenge with some ICT platforms. Finally, such services should be delivered via platforms that build upon local ICT access and usage, paying particular attention to the gender digital divide.},
   author = {Jenny C. Aker and Ishita Ghosh and Jenna Burrell},
   doi = {10.1111/AGEC.12301},
   issn = {15740862},
   journal = {Agricultural Economics (United Kingdom)},
   keywords = {Information technology,agriculture,impact evaluation},
   month = {11},
   pages = {35-48},
   publisher = {Blackwell Publishing Ltd},
   title = {The promise (and pitfalls) of ICT for agriculture initiatives},
   volume = {47},
   year = {2016},
}
@article{Haboudane2004,
   abstract = {A growing number of studies have focused on evaluating spectral indices in terms of their sensitivity to vegetation biophysical parameters, as well as to external factors affecting canopy reflectance. In this context, leaf and canopy radiative transfer models are valuable for modeling and understanding the behavior of such indices. In the present work, PROSPECT and SAILH models have been used to simulate a wide range of crop canopy reflectances in an attempt to study the sensitivity of a set of vegetation indices to green leaf area index (LAI), and to modify some of them in order to enhance their responsivity to LAI variations. The aim of the paper was to present a method for minimizing the effect of leaf chlorophyll content on the prediction of green LAI, and to develop new algorithms that adequately predict the LAI of crop canopies. Analyses based on both simulated and real hyperspectral data were carried out to compare performances of existing vegetation indices (Normalized Difference Vegetation Index [NDVI], Renormalized Difference Vegetation Index [RDVI], Modified Simple Ratio [MSR], Soil-Adjusted Vegetation Index [SAVI], Soil and Atmospherically Resistant Vegetation Index [SARVI], MSAVI, Triangular Vegetation Index [TVI], and Modified Chlorophyll Absorption Ratio Index [MCARI]) and to design new ones (MTVI1, MCARI1, MTVI2, and MCARI2) that are both less sensitive to chlorophyll content variations and linearly related to green LAI. Thorough analyses showed that the above existing vegetation indices were either sensitive to chlorophyll concentration changes or affected by saturation at high LAI levels. Conversely, two of the spectral indices developed as a part of this study, a modified triangular vegetation index (MTVI2) and a modified chlorophyll absorption ratio index (MCARI2), proved to be the best predictors of green LAI. Related predictive algorithms were tested on CASI (Compact Airborne Spectrographic Imager) hyperspectral images and, then, validated using ground truth measurements. The latter were collected simultaneously with image acquisition for different crop types (soybean, corn, and wheat), at different growth stages, and under various fertilization treatments. Prediction power analysis of proposed algorithms based on MCARI2 and MTVI2 resulted in agreements between modeled and ground measurement of non-destructive LAI, with coefficients of determination (r2) being 0.98 for soybean, 0.89 for corn, and 0.74 for wheat. The corresponding RMSE for LAI were estimated at 0.28, 0.46, and 0.85, respectively. © 2004 Elsevier Inc. All rights reserved.},
   author = {Driss Haboudane and John R. Miller and Elizabeth Pattey and Pablo J. Zarco-Tejada and Ian B. Strachan},
   doi = {10.1016/J.RSE.2003.12.013},
   issn = {00344257},
   issue = {3},
   journal = {Remote Sensing of Environment},
   keywords = {Chlorophyll content,Green LAI,Hyperspectral,Precision agriculture,Prediction algorithms,Spectral indices},
   month = {4},
   pages = {337-352},
   title = {Hyperspectral vegetation indices and novel algorithms for predicting green LAI of crop canopies: Modeling and validation in the context of precision agriculture},
   volume = {90},
   year = {2004},
}
@article{Zhang2012,
   abstract = {Precision agriculture (PA) is the application of geospatial techniques and sensors (e. g., geographic information systems, remote sensing, GPS) to identify variations in the field and to deal with them using alternative strategies. In particular, high-resolution satellite imagery is now more commonly used to study these variations for crop and soil conditions. However, the availability and the often prohibitive costs of such imagery would suggest an alternative product for this particular application in PA. Specifically, images taken by low altitude remote sensing platforms, or small unmanned aerial systems (UAS), are shown to be a potential alternative given their low cost of operation in environmental monitoring, high spatial and temporal resolution, and their high flexibility in image acquisition programming. Not surprisingly, there have been several recent studies in the application of UAS imagery for PA. The results of these studies would indicate that, to provide a reliable end product to farmers, advances in platform design, production, standardization of image georeferencing and mosaicing, and information extraction workflow are required. Moreover, it is suggested that such endeavors should involve the farmer, particularly in the process of field design, image acquisition, image interpretation and analysis. © 2012 Springer Science+Business Media, LLC.},
   author = {Chunhua Zhang and John M. Kovacs},
   doi = {10.1007/S11119-012-9274-5},
   issn = {13852256},
   issue = {6},
   journal = {Precision Agriculture},
   keywords = {Farmer participation,Low altitude remote sensing,UAS aviation regulations,UAS cameras,UAS limitations,UAS platforms,Unmanned aerial systems (UAS)},
   month = {12},
   pages = {693-712},
   title = {The application of small unmanned aerial systems for precision agriculture: A review},
   volume = {13},
   year = {2012},
}

@article{moscholios2020,
   abstract = {Climate change has introduced significant challenges that can affect multiple sectors, including the agricultural one. In particular, according to the Food and Agriculture Organization of the United Nations (FAO) and the International Telecommunication Union (ITU), the world population has to find new solutions to increase the food production by 70\% by 2050. The answer to this crucial challenge is the suitable adoption and utilisation of the Information and Communications Technology (ICT) services, offering capabilities that can increase the productivity of the agrochemical products, such as pesticides and fertilisers and at the same time, they should minimise the functional cost. More detailed, the advent of the Internet of Things (IoT) and specifically, the rapid evolution of the Unmanned Aerial Vehicles (UAVs) and Wireless Sensor Networks (WSNs) can lead to valuable and at the same time economic Precision Agriculture (PA) applications, such as aerial crop monitoring and smart spraying tasks. In this paper, we provide a survey regarding the potential use of UAVs in PA, focusing on 20 relevant applications. More specifically, first, we provide a detailed overview of PA, by describing its various aspects and technologies, such as soil mapping and production mapping as well as the role of the Global Positioning Systems (GPS) and Geographical Information Systems (GIS). Then, we discriminate and analyse the various types of UAVs based on their technical characteristics and payload. Finally, we investigate in detail 20 UAV applications that are devoted to either aerial crop monitoring processes or spraying tasks. For each application, we examine the methodology adopted, the proposed UAV architecture, the UAV type, as well as the UAV technical characteristics and payload.},
   author = {Panagiotis Radoglou-Grammatikis and Panagiotis Sarigiannidis and Thomas Lagkas and Ioannis Moscholios},
   doi = {10.1016/j.comnet.2020.107148},
   issn = {13891286},
   journal = {Computer Networks},
   keywords = {Precision agriculture (PA),Remote sensing (RS),Unmanned aerial vehicle (UAV)},
   month = {5},
   publisher = {Elsevier B.V.},
   title = {A compilation of UAV applications for precision agriculture},
   volume = {172},
   year = {2020},
}

@ARTICLE{Vepakomma2018,
	author = {Vepakomma, Udayalakshmi and Kneeshaw, Daniel D. and De Grandpré, Louis},
	title = {Influence of natural and anthropogenic linear canopy openings on forest structural patterns investigated using LiDAR},
	year = {2018},
	journal = {Forests},
	volume = {9},
	number = {9},
	doi = {10.3390/f9090540},
	%url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052969485&doi=10.3390%2ff9090540&partnerID=40&md5=56dc7a6291aeb1ae1c1e4cdd2b77d073},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	keywords = {misc},
	note = {Cited by: 11; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Natesan2019475,
	author = {Natesan, S. and Armenakis, C. and Vepakomma, U.},
	title = {Resnet-based tree species classification using uav images},
	year = {2019},
	journal = {International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences - ISPRS Archives},
	volume = {42},
	number = {2/W13},
	pages = {475 – 481},
	doi = {10.5194/isprs-archives-XLII-2-W13-475-2019},
	%url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067515490&doi=10.5194%2fisprs-archives-XLII-2-W13-475-2019&partnerID=40&md5=b10a439b3446a8cc44371a883c212cf7},
	type = {Conference paper},
	publication_stage = {Final},
	keywords = {rel_wor},
	source = {Scopus},
	note = {Cited by: 38; All Open Access, Gold Open Access, Green Open Access}
}


@misc{garcia-garcia_review_2017,
	title = {A Review on Deep Learning Techniques Applied to Semantic Segmentation},
	%url = {http://arxiv.org/abs/1704.06857},
	abstract = {Image semantic segmentation is more and more being of interest for computer vision and machine learning researchers. Many applications on the rise need accurate and efﬁcient segmentation mechanisms: autonomous driving, indoor navigation, and even virtual or augmented reality systems to name a few. This demand coincides with the rise of deep learning approaches in almost every ﬁeld or application target related to computer vision, including semantic segmentation or scene understanding. This paper provides a review on deep learning methods for semantic segmentation applied to various application areas. Firstly, we describe the terminology of this ﬁeld as well as mandatory background concepts. Next, the main datasets and challenges are exposed to help researchers decide which are the ones that best suit their needs and their targets. Then, existing methods are reviewed, highlighting their contributions and their signiﬁcance in the ﬁeld. Finally, quantitative results are given for the described methods and the datasets in which they were evaluated, following up with a discussion of the results. At last, we point out a set of promising future works and draw our own conclusions about the state of the art of semantic segmentation using deep learning techniques.},
	%number = {{arXiv}:1704.06857},
	publisher = {{arXiv}},
	author = {Garcia-Garcia, Alberto and Orts-Escolano, Sergio and Oprea, Sergiu and Villena-Martinez, Victor and Garcia-Rodriguez, Jose},
	%urldate = {2023-01-19},
	date = {2017-04-22},
	langid = {english},
	eprinttype = {arxiv},
	%eprint = {1704.06857 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
	file = {Garcia-Garcia et al. - 2017 - A Review on Deep Learning Techniques Applied to Se.pdf:/home/lore/Zotero/storage/N9N4FKY2/Garcia-Garcia et al. - 2017 - A Review on Deep Learning Techniques Applied to Se.pdf:application/pdf},
}

@article{moen_deep_2019,
	title = {Deep learning for cellular image analysis},
	volume = {16},
	issn = {1548-7091, 1548-7105},
	%url = {http://www.nature.com/articles/s41592-019-0403-1},
	doi = {10.1038/s41592-019-0403-1},
	pages = {1233--1246},
	number = {12},
	journaltitle = {Nature Methods},
	shortjournal = {Nat Methods},
	author = {Moen, Erick and Bannon, Dylan and Kudo, Takamasa and Graf, William and Covert, Markus and Van Valen, David},
	%urldate = {2023-03-18},
	date = {2019-12},
	langid = {english},
	file = {Moen et al. - 2019 - Deep learning for cellular image analysis.pdf:/home/lore/Zotero/storage/NTHU3WF9/Moen et al. - 2019 - Deep learning for cellular image analysis.pdf:application/pdf},
}

@article{seng2018computer,
  title={Computer Vision and Machine Learning for Viticulture Technology},
  author={Seng, Kah Phooi and Ang, Li-Minn and Schmidtke, Leigh M and Rogiers, Suzy Y},
  journal={IEEE Access},
  volume={6},
  pages={67494--67510},
  year={2018},
  publisher={IEEE}
}

@article{RAJ2021103107,
title = {A survey on the role of Internet of Things for adopting and promoting Agriculture 4.0},
journal = {Journal of Network and Computer Applications},
volume = {187},
pages = {103107},
year = {2021},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2021.103107},
%url = {https://www.sciencedirect.com/science/article/pii/S1084804521001284},
author = {Meghna Raj and Shashank Gupta and Vinay Chamola and Anubhav Elhence and Tanya Garg and Mohammed Atiquzzaman and Dusit Niyato},
abstract = {There is a rapid increase in the adoption of emerging technologies like the Internet of Things (IoT), Unmanned Aerial Vehicles (UAV), Internet of Underground Things (IoUT), Data analytics in the agriculture domain to meet the increased food demand to cater to the increasing population. Agriculture 4.0 is set to revolutionize agriculture productivity by using Precision Agriculture (PA), IoT, UAVs, IoUT, and other technologies to increase agriculture produce for growing demographics while addressing various farm-related issues. This survey provides a comprehensive overview of how multiple technologies such as IoT, UAVs, IoUT, Big Data Analytics, Deep Learning Techniques, and Machine Learning methods can be used to manage various farm-related operations. For each of these technologies, a detailed review is done on how the technology is being used in Agriculture 4.0. These discussions include an overview of relevant technologies, their use cases, existing case studies, and research works that demonstrate the use of these technologies in Agriculture 4.0. This paper also highlights the various future research gaps in the adoption of these technologies in Agriculture 4.0.}
}